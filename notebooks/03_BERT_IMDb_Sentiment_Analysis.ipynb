{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 style=\"text-align:center;\">IMDb Movie Review Sentiment Analysis (BERT)</h2>\n",
        "\n",
        "<h3 style=\"text-align:center;\">Part A: NLP-Final Project</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 1. Introduction <a name=\"introduction\"></a>\n",
        "\n",
        "This project performs sentiment analysis on IMDb movie reviews using deep learning techniques. We compare with advanced deep learning models (BERT)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvoIMOZEg1mf"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install tensorflow transformers pandas numpy matplotlib nltk seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR2TYIfBhQl4"
      },
      "outputs": [],
      "source": [
        "!pip install tf-keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33_oxoJxo7m6"
      },
      "source": [
        "### 1. Import Required Libraries\n",
        "\n",
        "First, we import all necessary Python libraries for data processing, modeling, and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SAq_rIKo-jX"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkjkOrdlpBG5"
      },
      "source": [
        "### 2. Dataset Loading\n",
        "\n",
        "We load the IMDB reviews dataset from a CSV file. The dataset contains movie reviews and their corresponding sentiment labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VunN2udBpDnr"
      },
      "outputs": [],
      "source": [
        "# Load dataset from CSV file\n",
        "df = pd.read_csv('data_imdb.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxXOoBsPpFaR"
      },
      "source": [
        "## 3. Data Cleaning\n",
        "\n",
        "We clean the text data by:\n",
        "- Converting to lowercase\n",
        "- Removing special characters and numbers\n",
        "- Removing extra whitespace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fle5ojPUpG8n"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "# Apply cleaning function to review column\n",
        "df['cleaned_review'] = df['review'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5YYNwS-pInt"
      },
      "source": [
        "### 4. Prepare Data for BERT\n",
        "\n",
        "We initialize the BERT tokenizer and encode our text data into a format suitable for BERT model input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHvbLiS3pKWb"
      },
      "outputs": [],
      "source": [
        "# Initialize BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to encode texts\n",
        "def encode_texts(texts, max_length=128):\n",
        "    return tokenizer(\n",
        "        texts.tolist(),\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "\n",
        "# Encode the cleaned reviews\n",
        "encoded_data = encode_texts(df['cleaned_review'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PVmuncrpeCd"
      },
      "source": [
        "## 4. Split Data into Training and Testing Sets\n",
        "\n",
        "We prepare our data for modeling by:\n",
        "- Converting sentiment labels to numerical values (0 and 1)\n",
        "- Splitting the dataset into training (80%) and testing (20%) sets\n",
        "- Using a fixed random state for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ga0Lgn4pfhs"
      },
      "outputs": [],
      "source": [
        "# Convert sentiment labels to numerical values\n",
        "df['sentiment'] = pd.factorize(df['sentiment'])[0]\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    encoded_data['input_ids'].numpy(),  # Convert to NumPy array before splitting\n",
        "    df['sentiment'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DerZuQz8phBf"
      },
      "source": [
        "## 5. Load Pre-trained BERT Model\n",
        "\n",
        "We load the pre-trained BERT base model (uncased version) and adapt it for our binary classification task by:\n",
        "- Using the base BERT architecture\n",
        "- Adding a classification head with 2 output units (positive/negative sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQC16xTWpiZq",
        "outputId": "22ce4144-12d5-413d-a94b-11cbf38b1782"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained BERT model for sequence classification\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_lXWoULpjoG"
      },
      "source": [
        "## 6. Compile the Model\n",
        "\n",
        "We configure the model for training with:\n",
        "- Adam optimizer with a small learning rate (2e-5) suitable for fine-tuning\n",
        "- Sparse categorical crossentropy loss function (since we have integer labels)\n",
        "- Accuracy as our evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLqDTqi5pkzl"
      },
      "outputs": [],
      "source": [
        "# Configure model training parameters\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KJX57FPpl71"
      },
      "source": [
        "## 7. Train the Model\n",
        "\n",
        "We train the model with:\n",
        "- Training data (X_train, y_train)\n",
        "- Validation on test set (X_test, y_test)\n",
        "- 1 epoch (for demonstration - typically would use more)\n",
        "- Batch size of 64 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtC4G8TBpnYT",
        "outputId": "896f61b0-cb84-48d0-88ab-bf01ce7040d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7b87fc4a3920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 309s 68s/step - loss: 0.7042 - accuracy: 0.4877 - val_loss: 0.6606 - val_accuracy: 0.6275\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_test, y_test),\n",
        "    epochs=1,\n",
        "    batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMoTU0uTpoeG"
      },
      "source": [
        "## 8. Evaluate Model Performance\n",
        "\n",
        "We evaluate the trained model on the test set to get:\n",
        "- Test loss value\n",
        "- Test accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZRMkmPypppB",
        "outputId": "461e560e-e3d9-4a78-9d43-2335dd78a3d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 23s 9s/step - loss: 0.6606 - accuracy: 0.6275\n",
            "Test Accuracy: 0.6275\n"
          ]
        }
      ],
      "source": [
        "# Evaluate model on test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Print test accuracy\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88HUMFX8qaeg"
      },
      "source": [
        "### 9. Save the Model\n",
        "\n",
        "We save the trained model and tokenizer for future use, which allows us to:\n",
        "- Avoid retraining the model each time\n",
        "- Deploy the model in production\n",
        "- Share the model with others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU5dAsWFqdHY",
        "outputId": "70186403-82fc-49c4-8644-146889dc2085"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('sentiment_bert_model/tokenizer_config.json',\n",
              " 'sentiment_bert_model/special_tokens_map.json',\n",
              " 'sentiment_bert_model/vocab.txt',\n",
              " 'sentiment_bert_model/added_tokens.json')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the trained model and tokenizer\n",
        "model.save_pretrained('sentiment_bert_model')\n",
        "tokenizer.save_pretrained('sentiment_bert_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKhW2Y7Dqeh-"
      },
      "source": [
        "### 10. Load the Saved Model\n",
        "\n",
        "We demonstrate how to load the saved model, which is useful for:\n",
        "- Making predictions without retraining\n",
        "- Continuing training later\n",
        "- Deploying the model in different environments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJV5JAYqjkN",
        "outputId": "ad45a26a-393f-4c23-b5f2-4d33c3e3b019"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at sentiment_bert_model were not used when initializing TFBertForSequenceClassification: ['dropout_303']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at sentiment_bert_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model and tokenizer\n",
        "loaded_model = TFBertForSequenceClassification.from_pretrained('sentiment_bert_model')\n",
        "loaded_tokenizer = BertTokenizer.from_pretrained('sentiment_bert_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIQ-cuQIqk1L"
      },
      "source": [
        "## 11. Test with Sample Data\n",
        "\n",
        "We create a prediction function that:\n",
        "1. Cleans input text\n",
        "2. Tokenizes the text for BERT\n",
        "3. Makes sentiment predictions\n",
        "4. Returns both the prediction and confidence score\n",
        "\n",
        "We then test this function with sample reviews."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqsNW6pfqmF_"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text, model, tokenizer):\n",
        "    # Clean and tokenize the text\n",
        "    cleaned_text = clean_text(text)\n",
        "    inputs = tokenizer(\n",
        "        cleaned_text,\n",
        "        max_length=128,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_tensors='tf'\n",
        "    )\n",
        "\n",
        "    # Make prediction\n",
        "    outputs = model(inputs)\n",
        "    logits = outputs.logits\n",
        "    probabilities = tf.nn.softmax(logits, axis=1)\n",
        "    predicted_class = tf.argmax(probabilities, axis=1).numpy()[0]\n",
        "\n",
        "    # Get confidence score\n",
        "    confidence = np.max(probabilities.numpy())\n",
        "\n",
        "    return \"Positive\" if predicted_class == 1 else \"Negative\", confidence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztYz3bEVqnYy"
      },
      "source": [
        "## 12. Sample Predictions\n",
        "\n",
        "We test our model with diverse sample reviews to:\n",
        "- Verify model performance\n",
        "- Show different confidence levels\n",
        "- Demonstrate real-world usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKgtpN5pqooz",
        "outputId": "dfffdbb0-f927-4b9c-f8f8-44db0d9df435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Predictions:\n",
            "Review: This movie was absolutely fantastic! The acting was superb....\n",
            "Predicted Sentiment: Negative (Confidence: 0.62)\n",
            "--------------------------------------------------------------------------------\n",
            "Review: I hated this film. Worst two hours of my life....\n",
            "Predicted Sentiment: Negative (Confidence: 0.62)\n",
            "--------------------------------------------------------------------------------\n",
            "Review: The plot was predictable but the cinematography made up for ...\n",
            "Predicted Sentiment: Negative (Confidence: 0.65)\n",
            "--------------------------------------------------------------------------------\n",
            "Review: Not worth the money. Would not recommend to anyone....\n",
            "Predicted Sentiment: Negative (Confidence: 0.63)\n",
            "--------------------------------------------------------------------------------\n",
            "Review: The director did an amazing job with this adaptation....\n",
            "Predicted Sentiment: Negative (Confidence: 0.63)\n",
            "--------------------------------------------------------------------------------\n",
            "Review: Boring from start to finish. Fell asleep halfway through....\n",
            "Predicted Sentiment: Negative (Confidence: 0.64)\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Sample reviews for testing\n",
        "sample_reviews = [\n",
        "    \"This movie was absolutely fantastic! The acting was superb.\",\n",
        "    \"I hated this film. Worst two hours of my life.\",\n",
        "    \"The plot was predictable but the cinematography made up for it.\",\n",
        "    \"Not worth the money. Would not recommend to anyone.\",\n",
        "    \"The director did an amazing job with this adaptation.\",\n",
        "    \"Boring from start to finish. Fell asleep halfway through.\"\n",
        "]\n",
        "\n",
        "# Make predictions and display results\n",
        "print(\"\\nSample Predictions:\")\n",
        "for review in sample_reviews:\n",
        "    sentiment, confidence = predict_sentiment(review, loaded_model, loaded_tokenizer)\n",
        "    print(f\"Review: {review[:60]}...\")\n",
        "    print(f\"Predicted Sentiment: {sentiment} (Confidence: {confidence:.2f})\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63KvxYWZ3deb"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
